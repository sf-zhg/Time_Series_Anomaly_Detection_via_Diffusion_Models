{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QKfEqoNKnV0",
        "outputId": "56564102-540c-4022-8b04-aebed8e6d591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/applied_DL\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "!source /content/drive/MyDrive/colab_env/bin/activate\n",
        "%cd /content/drive/MyDrive/applied_DL/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_80y5b5SLGw9",
        "outputId": "3e404a51-c414-4144-c680-6972714f4f2b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.2.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.66.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.7.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.58.1)\n",
            "Collecting opensimplex (from -r requirements.txt (line 9))\n",
            "  Downloading opensimplex-0.4.5-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.0/268.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from -r requirements.txt (line 10))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX (from -r requirements.txt (line 11))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (7.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 2)) (2023.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->-r requirements.txt (line 8)) (0.41.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 11)) (3.20.3)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 12)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 12)) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\n",
            "Installing collected packages: tensorboardX, opensimplex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, einops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed einops-0.7.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 opensimplex-0.4.5 tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "from TimeSeriesDiffusion.data.get_data import get_dataset\n",
        "from TimeSeriesDiffusion.trainer import trainer\n",
        "from TimeSeriesDiffusion.models.unet import Unet\n",
        "from TimeSeriesDiffusion.models.convnet import ConvNetWithTimeEmbeddings\n",
        "from TimeSeriesDiffusion.diffusion_model.diffusion_ingridients import DiffusionIngridients\n",
        "from TimeSeriesDiffusion.diffusion_model.inference import generative_inference\n",
        "\n",
        "# Define arguments\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.dataset = \"sine_wave\"  # Change this to your dataset name\n",
        "        self.data_path = \"TimeSeriesDiffusion/raw_data_csv\"  # Change this to the path of your data\n",
        "        self.optimizer = \"adam\"\n",
        "        self.batch_size = 16\n",
        "        self.learning_rate = 0.01\n",
        "        self.epochs = 5\n",
        "        self.time_steps = 10\n",
        "        self.beta_lower = 0.01\n",
        "        self.beta_upper = 0.99\n",
        "        self.scheduler = \"linear\"\n",
        "        self.noise = \"gaussian\"\n",
        "        self.loss = \"l1\"\n",
        "        self.dim = 128\n",
        "        self.num_samples = 2\n",
        "        self.csv_path = \"results_csv_and_plots\"\n",
        "        self.noisy_file_name = \"noisy\"\n",
        "        self.gen_file_name = \"gen\"\n",
        "        self.log_schedule = 5\n",
        "        self.anno_threshold = 0.1\n",
        "        self.model_arch = 'convnet'\n",
        "\n",
        "args = Args()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "full_root = args.data_path\n",
        "train_data, test_data = get_dataset(dataset=args.dataset, root=full_root)\n",
        "\n",
        "train_loader = DataLoader(train_data,\n",
        "                          batch_size=args.batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1,\n",
        "                          pin_memory=True,\n",
        "                          drop_last=True)\n",
        "\n",
        "test_loader = DataLoader(test_data,\n",
        "                         batch_size = args.batch_size,\n",
        "                         shuffle = False,\n",
        "                         num_workers = 1,\n",
        "                         pin_memory = True)\n",
        "\n",
        "for batch in train_loader:\n",
        "    x, _ = batch\n",
        "    break\n",
        "\n",
        "if args.model_arch == 'convnet':\n",
        "  model = ConvNetWithTimeEmbeddings(dim = 32)\n",
        "elif args.model_arch == 'unet':\n",
        "  model = Unet(dims = 32)\n",
        "\n",
        "model = nn.DataParallel(model)\n",
        "\n",
        "diff = DiffusionIngridients(\n",
        "    model=model,\n",
        "    time_steps=args.time_steps,\n",
        "    beta_lower=args.beta_lower,\n",
        "    beta_upper=args.beta_upper,\n",
        "    scheduler=args.scheduler,\n",
        "    noise=args.noise,\n",
        "    loss=args.loss,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "if not os.path.exists(\"results\"):\n",
        "    os.makedirs(\"results\")\n",
        "\n",
        "if not os.path.exists(args.csv_path):\n",
        "    os.makedirs(args.csv_path)\n",
        "\n",
        "writer = SummaryWriter(comment=\"_pretraining\")\n",
        "t0 = time.time()\n",
        "\n",
        "# training loop\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train_loss = trainer(\n",
        "        data_loader=train_loader,\n",
        "        optimizer=args.optimizer,\n",
        "        batch_size=args.batch_size,\n",
        "        learning_rate=args.learning_rate,\n",
        "        epochs=args.epochs,\n",
        "        time_steps=args.time_steps,\n",
        "        loss=args.loss,\n",
        "        diffusion_model=diff,\n",
        "    )\n",
        "    writer.add_scalar(\"Train/Loss\", train_loss, epoch)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        torch.save(\n",
        "            model.module.state_dict(), \"results/pretraining_{}.pth\".format(epoch)\n",
        "        )\n",
        "\n",
        "        # generate result\n",
        "        a = generative_inference(\n",
        "            diffusion_model=diff,\n",
        "            test_loader=test_loader,\n",
        "            num_samples=args.num_samples,\n",
        "            csv_path=args.csv_path,\n",
        "            generated_file_name=args.gen_file_name,\n",
        "            noisy_file_name=args.noisy_file_name,\n",
        "            device=device,\n",
        "            noise=args.noise,\n",
        "            log_schedule=args.log_schedule,\n",
        "            anno_threshold=args.anno_threshold,\n",
        "            epoch=epoch\n",
        "        )\n",
        "        print(a)\n",
        "\n",
        "t1 = time.time() - t0\n",
        "print(\"Time elapsed in hours:\", t1 / 3600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VEZbElXpNWS",
        "outputId": "dab9e9ec-9690-4334-e47b-59998ae293eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  8.73it/s, Loss=2.31]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running generative inference for epoch: 1\n",
            "Sample data loaded\n",
            "Test data shape: torch.Size([31, 16])\n",
            "Test labels shape: torch.Size([31])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sampling loop time step: 100%|██████████| 10/10 [00:00<00:00, 6973.07it/s]\n",
            "/content/drive/MyDrive/applied_DL/TimeSeriesDiffusion/diffusion_model/generator_helpers.py:174: UserWarning: Tight layout not applied. tight_layout cannot make axes height small enough to accommodate all axes decorations.\n",
            "  plt.tight_layout()\n",
            "/content/drive/MyDrive/applied_DL/TimeSeriesDiffusion/diffusion_model/generator_helpers.py:192: UserWarning: Tight layout not applied. tight_layout cannot make axes height small enough to accommodate all axes decorations.\n",
            "  plt.tight_layout()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello there\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 27.85it/s, Loss=2.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running generative inference for epoch: 2\n",
            "Sample data loaded\n",
            "Test data shape: torch.Size([31, 16])\n",
            "Test labels shape: torch.Size([31])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sampling loop time step: 100%|██████████| 10/10 [00:00<00:00, 10804.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello there\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 23.02it/s, Loss=2.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running generative inference for epoch: 3\n",
            "Sample data loaded\n",
            "Test data shape: torch.Size([31, 16])\n",
            "Test labels shape: torch.Size([31])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sampling loop time step: 100%|██████████| 10/10 [00:00<00:00, 2988.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello there\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 25.89it/s, Loss=2.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running generative inference for epoch: 4\n",
            "Sample data loaded\n",
            "Test data shape: torch.Size([31, 16])\n",
            "Test labels shape: torch.Size([31])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sampling loop time step: 100%|██████████| 10/10 [00:00<00:00, 6252.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello there\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 24.08it/s, Loss=1.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running generative inference for epoch: 5\n",
            "Sample data loaded\n",
            "Test data shape: torch.Size([31, 16])\n",
            "Test labels shape: torch.Size([31])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sampling loop time step: 100%|██████████| 10/10 [00:00<00:00, 10776.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello there\n",
            "Time elapsed in hours: 0.02795210745599535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FNZdNf9-fRRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PL4rOY7IR8ym"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m2K69foSpTKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-N7j_3x6pctB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nPMyUhew_zO4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}